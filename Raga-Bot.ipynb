{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkvi7jGbM8yE",
        "outputId": "28e3650d-09ba-46f0-f6b2-32544e136803"
      },
      "outputs": [],
      "source": [
        "#1 Importing Relevant Libraries\n",
        "import json\n",
        "import string\n",
        "import random \n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "import tkinter as tk\n",
        "from tkinter import scrolledtext\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_nltk_data():\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')\n",
        "    \n",
        "    try:\n",
        "        nltk.data.find('corpora/wordnet')\n",
        "    except LookupError:\n",
        "        nltk.download('wordnet')\n",
        "\n",
        "# Download NLTK data if necessary\n",
        "download_nltk_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#2 Loading the Dataset: intents.json\n",
        "\n",
        "with open(r'intents.json', encoding='utf-8') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlfhvlVMGMgA"
      },
      "outputs": [],
      "source": [
        "#3 Extracting data_X(features) and data_Y(Target)\n",
        "\n",
        "words = [] #For Bow model/ vocabulary for patterns\n",
        "classes = [] #For Bow  model/ vocabulary for tags\n",
        "data_X = [] #For storing each pattern\n",
        "data_y = [] #For storing tag corresponding to each pattern in data_X \n",
        "# Iterating over all the intents\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        tokens = nltk.word_tokenize(pattern) # tokenize each pattern \n",
        "        words.extend(tokens) #and append tokens to words\n",
        "        data_X.append(pattern) #appending pattern to data_X\n",
        "        data_y.append(intent[\"tag\"]) ,# appending the associated tag to each pattern \n",
        "    \n",
        "    # adding the tag to the classes if it's not there already \n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# initializing lemmatizer to get stem of words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# lemmatize all the words in the vocab and convert them to lowercase\n",
        "# if the words don't appear in punctuation\n",
        "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
        "# sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplicates occur\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxXzyJNNR17c"
      },
      "outputs": [],
      "source": [
        "# 5 Text to Numbers\n",
        "training = []\n",
        "out_empty = [0] * len(classes)\n",
        "# creating the bag of words model\n",
        "for idx, doc in enumerate(data_X):\n",
        "    bow = []\n",
        "    text = lemmatizer.lemmatize(doc.lower())\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "    # mark the index of class that the current pattern is associated\n",
        "    # to\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(data_y[idx])] = 1\n",
        "    # add the one hot encoded BoW and associated classes to training \n",
        "    training.append([bow, output_row])\n",
        "# shuffle the data and convert it to an array\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "# split the features and target labels\n",
        "train_X = np.array(list(training[:, 0]))\n",
        "train_Y = np.array(list(training[:, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Q343LiR9w1",
        "outputId": "8eff8feb-d4ab-426a-c091-3530cc69bb6c"
      },
      "outputs": [],
      "source": [
        "#6 The Neural Network Model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_X[0]),), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_Y[0]), activation = \"softmax\"))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x=train_X, y=train_Y, epochs=150, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#7 Fetching from database\n",
        "def get_workout(workout_name, level):\n",
        "    connection = None  # Initialize connection variable\n",
        "    try:\n",
        "        connection = mysql.connector.connect(\n",
        "            host='localhost',\n",
        "            database='workouts_db',\n",
        "            user='root', \n",
        "            password='1234'\n",
        "        )\n",
        "        if connection.is_connected():\n",
        "            cursor = connection.cursor()\n",
        "            query = f\"SELECT * FROM {workout_name} WHERE level = '{level}'\"\n",
        "            cursor.execute(query)\n",
        "            results = cursor.fetchall()\n",
        "            return results\n",
        "    except Error as e:\n",
        "        return [f\"Error connecting to database: {e}\"]\n",
        "    finally:\n",
        "        if connection is not None and connection.is_connected():\n",
        "            cursor.close()\n",
        "            connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjWR6_B7SJ-_"
      },
      "outputs": [],
      "source": [
        "#8 Preprocessing the Input\n",
        "\n",
        "def clean_text(text): \n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "def bag_of_words(text, vocab): \n",
        "  tokens = clean_text(text)\n",
        "  bow = [0] * len(vocab)\n",
        "  for w in tokens: \n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w: \n",
        "        bow[idx] = 1\n",
        "  return np.array(bow)\n",
        "\n",
        "def pred_class(text, vocab, labels, context, intents):\n",
        "  bow = bag_of_words(text, vocab)\n",
        "  result = model.predict(np.array([bow]))[0]  # Extracting probabilities\n",
        "  thresh = 0.5\n",
        "  y_pred = [[indx, res] for indx, res in enumerate(result) if res > thresh]\n",
        "  y_pred.sort(key=lambda x: x[1], reverse=True)  # Sorting by values of probability in decreasing order\n",
        "  return_list = []\n",
        "  \n",
        "  for r in y_pred:\n",
        "      for intent in intents:\n",
        "          if intent['tag'] == labels[r[0]]:\n",
        "              if intent['context_required'] == \"\" or intent['context_required'] == context:\n",
        "                  return_list.append(labels[r[0]])  # Contains labels(tags) for highest probability \n",
        "\n",
        "  return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json, context, level, root):\n",
        "  list_of_intents = intents_json[\"intents\"]\n",
        "  if not intents_list: \n",
        "      tag = 'noanswer'\n",
        "  else:\n",
        "      tag = intents_list[0]\n",
        "\n",
        "  for intent in list_of_intents:\n",
        "      if intent[\"tag\"] == tag:\n",
        "          if tag in [\"chest_arms\", \"abs\", \"legs\", \"full_body\", \"cardio\"]:\n",
        "              result = random.choice(intent[\"responses\"])\n",
        "              workouts = get_workout(tag, level)\n",
        "              for workout in workouts:\n",
        "                id_w, exercise_name, target, repetitions, instructions, level = workout\n",
        "                result += \"\".join(f\"{exercise_name}\\n *Target: {target}\\n *Repetisi: {repetitions}\\n *Instruksi: {instructions}\\n \")\n",
        "          elif tag == \"level\":\n",
        "              level_selector = LevelSelector(root)\n",
        "              root.wait_window(level_selector)  # Wait for the level selector window to close\n",
        "\n",
        "              if level_selector.level:\n",
        "                  level = level_selector.level\n",
        "                  result = f\"Tingkatan Anda sekarang {level}. \\n\"\n",
        "              else:\n",
        "                  result = \"Anda tidak memilih tingkatan baru. \\n\"\n",
        "          \n",
        "          else:\n",
        "              result = random.choice(intent[\"responses\"])\n",
        "          context = intent[\"context_set\"]  # update context\n",
        "          break\n",
        "  else:\n",
        "      noanswer_tag = [intent for intent in list_of_intents if intent[\"tag\"] == \"noanswer\"]\n",
        "      result = random.choice(noanswer_tag[0][\"responses\"])\n",
        "      context = \"\"  # reset context if noanswer\n",
        "\n",
        "  return result, tag, context, level\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChatApp(tk.Tk):\n",
        "    def __init__(self, level):\n",
        "        super().__init__()\n",
        "        self.title(\"Raga Chatbot\")\n",
        "        self.geometry(\"500x600\")\n",
        "\n",
        "        # Center the window\n",
        "        window_width = 500\n",
        "        window_height = 600\n",
        "        screen_width = self.winfo_screenwidth()\n",
        "        screen_height = self.winfo_screenheight()\n",
        "        x = (screen_width // 2) - (window_width // 2)\n",
        "        y = (screen_height // 2) - (window_height // 2)\n",
        "        self.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
        "\n",
        "        # Set styles\n",
        "        self.configure(bg='#040507')\n",
        "        font = (\"Helvetica\", 12)\n",
        "        self.transcript_font = (\"Helvetica\", 12)\n",
        "        self.input_font = (\"Helvetica\", 12)\n",
        "        self.button_font = (\"Helvetica\", 12, \"bold\")\n",
        "\n",
        "        # Create chat transcript area\n",
        "        self.transcript_area = scrolledtext.ScrolledText(self, wrap=tk.WORD, width=50, height=20, font=self.transcript_font, bg=\"#0d1117\", state=\"disabled\", fg=\"white\")\n",
        "        self.transcript_area.grid(row=0, column=0, padx=10, pady=10)\n",
        "\n",
        "        # Create input area\n",
        "        self.input_area = tk.Text(self, wrap=tk.WORD, width=50, height=3, font=self.input_font, bg=\"#0d1117\", bd=2, relief=\"groove\", fg=\"white\")\n",
        "        self.input_area.grid(row=1, column=0, padx=10, pady=10)\n",
        "\n",
        "        # Create send button\n",
        "        self.send_button = tk.Button(self, text=\"Send\", font=self.button_font, bg=\"#4CAF50\", fg=\"white\", command=self.send_message)\n",
        "        self.send_button.grid(row=2, column=0, padx=10, pady=10, sticky=\"e\")\n",
        "\n",
        "        # Initialize context\n",
        "        self.context = \"\"\n",
        "        self.level = level  # Set level based on user choice\n",
        "\n",
        "    def send_message(self):\n",
        "        message = self.input_area.get(\"1.0\", tk.END).strip()\n",
        "        if message:\n",
        "            self.transcript_area.configure(state=\"normal\")\n",
        "            self.transcript_area.insert(tk.END, \"You: \" + message + \"\\n\")\n",
        "            self.transcript_area.configure(state=\"disabled\")\n",
        "            self.input_area.delete(\"1.0\", tk.END)\n",
        "\n",
        "            # Get response from chatbot\n",
        "            intents_list = pred_class(message, words, classes, self.context, data[\"intents\"])\n",
        "            response, tagged, self.context, self.level = get_response(intents_list, data, self.context, self.level, self)\n",
        "            \n",
        "            self.transcript_area.configure(state=\"normal\")\n",
        "            self.transcript_area.insert(tk.END, \"Raga: \" + response + \"\\n\")\n",
        "            self.transcript_area.configure(state=\"disabled\")\n",
        "\n",
        "            if tagged == \"goodbye\":\n",
        "                self.destroy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LevelSelector(tk.Toplevel):\n",
        "    def __init__(self, parent):\n",
        "        super().__init__(parent)\n",
        "        self.title(\"Level Selector\")\n",
        "        self.geometry(\"300x200\")\n",
        "        self.configure(bg='#040507')\n",
        "        self.button_font = (\"Helvetica\", 10)\n",
        "        self.label_font = (\"Helvetica\", 12)\n",
        "\n",
        "        window_width = 300\n",
        "        window_height = 200\n",
        "        screen_width = self.winfo_screenwidth()\n",
        "        screen_height = self.winfo_screenheight()\n",
        "        x = (screen_width // 2) - (window_width // 2)\n",
        "        y = (screen_height // 2) - (window_height // 2)\n",
        "        self.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
        "        \n",
        "        label = tk.Label(self, font = self.label_font, fg = \"white\", bg = \"#040507\", text=\"Pilihlah tingkat olahraga dirimu!\")\n",
        "        label.pack(pady=20)\n",
        "        \n",
        "        beginner_button = tk.Button(self, font = self.button_font, text=\"Beginner\", bg=\"#4CAF50\", fg=\"white\", command=lambda: self.select_level(\"beginner\"))\n",
        "        beginner_button.pack(pady=5)\n",
        "        \n",
        "        intermediate_button = tk.Button(self, font = self.button_font, text=\"Intermediate\", bg=\"#4CAF50\", fg=\"white\", command=lambda: self.select_level(\"intermediate\"))\n",
        "        intermediate_button.pack(pady=5)\n",
        "        \n",
        "        advanced_button = tk.Button(self, font = self.button_font, text=\"Advanced\", bg=\"#4CAF50\", fg=\"white\", command=lambda: self.select_level(\"advanced\"))\n",
        "        advanced_button.pack(pady=5)\n",
        "        \n",
        "        self.level = None\n",
        "    \n",
        "    def select_level(self, level):\n",
        "        self.level = level\n",
        "        self.destroy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQLRSslMSQ9s",
        "outputId": "a902746b-a34c-47b2-fb63-8e2643937300"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    root = ChatApp(None)\n",
        "    root.withdraw()  # Hide the main window\n",
        "\n",
        "    level_selector = LevelSelector(root)\n",
        "    root.wait_window(level_selector)  # Wait for the level selector window to close\n",
        "\n",
        "    if level_selector.level:\n",
        "        root.level = level_selector.level\n",
        "        root.deiconify()  # Show the main window\n",
        "        root.mainloop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ChatBot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
